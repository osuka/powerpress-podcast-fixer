#!/bin/python

import sys
import urllib
from datetime import timezone
from typing import List
from lxml import html
from feedgen.feed import FeedGenerator
import requests
import dateparser

# Base structure:
#
# .single_archiveblog
#   .archiveblog_left
#     img.avatar [src]
#     h5.author_name [text]
#     p.postdate [text]
#   .archiveblog_right
#     h2 > a.bookmark
#     p  [text]
#     .powerpress_player
#       audio
#         source [src]


site_list = [
    {"url": "http://podcast.radiobronka.info/category/todo-es-mentira/",
     "page_template": 'http://podcast.radiobronka.info/category/todo-es-mentira/page/{page}/',
     "feedname": "podcast-todo-es-mentira"
     }
]

for site in site_list:

    print(f"Processing {site}")
    fg = FeedGenerator()
    fg.load_extension('podcast')
    fg.podcast.itunes_category('Music', 'Music Commentary')
    fg.id(site["url"])
    fg.link(href=site["url"], rel='alternate')
    fg.language('es')

    # iterate over pages if we know there's a template, else just the one
    for index in range(1, 1 if not "page_template" in site else 50):
        url = site["page_template"].format(page=index)
        print(f" - Loading {url}")
        page = requests.get(url, allow_redirects=True,)
        if page.status_code == 404:
            break

        contents = page.content

        tree = html.fromstring(contents)

        # use first page for feed information
        if index == 1:
            site_title = tree.xpath("//title/text()")[0]
            fg.title(site_title)
            avatar = tree.xpath(
                '//img[contains(concat(" ", @class, " "), " avatar ")]/@src')[0]
            author = tree.xpath('//h5[@class="author_name"]/text()')[0]
            fg.logo(avatar)
            fg.author({'name': author})  # 'email':'john@example.de'
            fg.description(
                f"Autogenerated podcast for Radio program {site_title} from {site['url']}")
            # fg.subtitle('This is a cool feed!')
            # fg.link( href='http://larskiesow.de/test.atom', rel='self' )

        blogs: List[html.Element] = tree.xpath(
            '//div[contains(concat(" ", @class, " "), " single_archiveblog ")]')

        for blog in blogs:
            id = blog.xpath("@id")

            post_date = blog.xpath('//p[@class="postdate"]/text()')[0]

            right = blog.xpath('div[@class="archiveblog_right"]')
            if not right:
                continue
            right = right[0]
            left = blog.xpath('div[@class="archiveblog_left"]')[0]

            title_element = right.xpath('h2/a[@rel="bookmark"]')[0]
            blog_title = title_element.text
            blog_href = title_element.attrib["href"]

            body_list = right.xpath('p/text()')
            body = "\n".join(body_list)

            source = right.xpath(
                'div[@class="powerpress_player"]/audio/source/@src')
            if not source:
                # some entries have:
                # div.powerpress_player
                #   a [href points to an m3u]
                source = right.xpath(
                'div[@class="powerpress_player"]/a[substring(@href, string-length(@href) - 3) = ".m3u"]/@href')
                if not source:
                    print(f"  * error in {blog_title}, {blog_href} found in {url}")
                    # some other formats found that we won't care about:
                    # href=http://media.blubrry.com/radiobronka/p/www.archive.org/details/TodoEsMentira20DeMarzo2010
                    # href=https://media.blubrry.com/radiobronka/p/archive.org/compress/01Pista1_201510/formats=VBR%20MP3&file=/01Pista1_201510.zip
                    # href=http://media.blubrry.com/radiobronka/p/www.archive.org/download/TodoEsMentira12DeAbril2008/TodoEsMentira12DeAbril2008_64kb_mp3.zip
                    continue
                else:
                    source = source[0]
                    # fetch the m3u and retrieve media - there's only one actually
                    m3u = requests.get(source, allow_redirects=True)
                    source = m3u.text.splitlines()[0]
                    type="audio/mpeg"
            else:
                source = source[0]
                type = right.xpath(
                    'div[@class="powerpress_player"]/audio/source/@type')[0]


            fe = fg.add_entry(order="append")
            fe.guid(blog_href, permalink=True)
            fe.title(blog_title)
            fe.description(body)
            fe.enclosure(source, 0, type)
            fe.link(href=blog_href)
            fe.updated(dateparser.parse(
                post_date).replace(tzinfo=timezone.utc))

    # write output
    file_name = f"{site['feedname']}-rss.xml"
    print(f"- Generated {file_name}")
    fg.rss_file(file_name)
